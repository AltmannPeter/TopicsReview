{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnA68eC6/cgqYVWG8346rS"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Combined presentations and Proof of Association\n",
        "\n",
        "Disclamer: This text is not intended to communicate a favored approach; but to guide a fruitful discussion. Furthermore, the text does not consider protocol choices already made, but may reference these when suitable.\n",
        "\n",
        "## Defining combined presentations\n",
        "\n",
        "[Topic K](https://github.com/eu-digital-identity-wallet/eudi-doc-architecture-and-reference-framework/issues/341) defines *combined presentations* and aims to outline implementation requirements.\n",
        "\n",
        "A slight refinement could better clarify security requirements and shift the focus to what the Verifier must *determine* (rather than attribute requests and consolidation).\n",
        "\n",
        "I propose defining a combined presentation as a transaction where at least two attributes from distinct attestations are presented to a Verifier so that the Verifier:\n",
        "\n",
        "1. determines whether the two attributes describe the same identity subject (*Identity Binding*), and\n",
        "2. ensures that the attributes are properly paired when presented (*Valid Composition*).\n",
        "\n",
        "The first requirement is straightforward, but the second is more nuanced. **Example A** illustrates why proper pairing is crucial (see also the [VC implementation guidelines \"selective disclosure\" subsection under ZKP](https://www.w3.org/TR/vc-imp-guide/#zero-knowledge-proofs)).\n",
        "\n",
        "> **Example A: The risk of improper attribute pairing**  \n",
        "The following two attestations describe the same identity subject:\n",
        "```\n",
        "{\n",
        "  \"attestation_id\": 1,\n",
        "  \"employer\": \"UK ltd\",\n",
        "  \"role\": \"CEO\",\n",
        "  \"name\": \"John Doe\"\n",
        "}\n",
        "{\n",
        "  \"attestation_id\": 2,\n",
        "  \"employer\": \"SE ABB\",\n",
        "  \"role\": \"Board member\"\n",
        "}\n",
        "```\n",
        "A **valid composition** maintains logical consistency:\n",
        "```\n",
        "{\n",
        "  \"employer\": \"SE ABB\",\n",
        "  \"name\": \"John Doe\"\n",
        "}\n",
        "```\n",
        "The following example is **NOT a valid composition** as it improperly pairs the `employer` and `role` values.\n",
        "```\n",
        "{\n",
        "  \"employer\": \"SE ABB\",\n",
        "  \"role\": \"CEO\"\n",
        "}\n",
        "```\n",
        "## Security requirements for combined presentations\n",
        "\n",
        "With the above in mind, the following security requirements must be met:\n",
        "\n",
        "1. **Identity Binding**: The Verifier must determine whether the presented attributes refer to the same identity subject.\n",
        "  * Note that this does not mean the attributes must describe the same identity subjectâ€”only that the Verifier can assess whether they do.\n",
        "  * Some combined presentations may include attributes from different identity subjects (e.g., a child and their legal guardian).\n",
        "2. **Valid Composition**: The Verifier must ensure that all attributes are properly paired according to their original attestations and **not** combined in a way that alters their intended meaning.\n",
        "\n",
        "## Achieving Identity Binding\n",
        "\n",
        "To determine Identity Binding, there needs to be some sort of Proof of Association between the presented attributes. I am aware of the following general solutions:\n",
        "\n",
        "### Session-based PoA\n",
        "\n",
        "Session-based PoA ensures that all attestations sent within a secured session originate from the same certified WSCD and refer to the same identity subject. This approach is useful when a Verifier can validate multiple attestations within a session.\n",
        "\n",
        "Session-based PoA requires that:\n",
        "\n",
        "1. The WSCD must protect the User's attestations, not just the cryptographic keys.\n",
        "2. The WSCD must only protect attestations that describe the same identity subject.\n",
        "3. The Verifier must bind the secure session to a User identity and WSCD.\n",
        "\n",
        "I am not familiar enough with session-based PoA approaches to provide a detailed list of drawbacks and benefits, but some considerations may include:\n",
        "\n",
        "* **Questionable offline support**. Given that a session must exist for PoA, offline support is difficult.\n",
        "* **Lightweight**. No need for cryptography beyond establishing a secure session as all attestations sent over the session are assumed to be associated.\n",
        "* **Adaptable to existing protocols**. Existing standards like OAuth 2.0, OIDC, and TLS session binding can be leveraged but I am unaware of a widely deployed session-based PoA-specific standard.\n",
        "\n",
        "### Claim-based PoA\n",
        "\n",
        "Claim-based binding allows a Verifier to perform identity binding solely based on the claims presented by the User. There are two general approaches:\n",
        "\n",
        "1. Unblinded PoA inputs (Verifier linkable)\n",
        "2. Blinded PoA inputs (Verifier unlinkable)\n",
        "\n",
        "Since Verifier unlinkability is a requirement, we will only consider the Verifier unlinkable blinded PoA inputs below.\n",
        "\n",
        "> Note: Issuer unlinkability is irrelevant if the attestation includes other Issuer-linkable correlation handles (e.g., salt values, public keys etc.).\n",
        "\n",
        "To achieve Verifier unlinkability, the User only present blinded claim statements. Blinded claim statements are particularly suitable when attestation Issuers rely on a attestation (e.g., a PID) to identify the User before issuing new attestations. In this model, Issuers and Verifiers receive different identifying attestations:\n",
        "\n",
        "* Issuers recieve a PID that contains a claim statement with a unique value (only shown to Issuers). Each Issuer blinds the claim statement before embedding it in the issued attestation.\n",
        "* The User reveals only blinded claim statements with a PoA to a Verifier.\n",
        "\n",
        "During verification, the User must prove that the blinded claim statements are equivalent in some way (c.f. Appendix A for a ZKP-based approach that offers third party repudiation).\n",
        "\n",
        "Some limitations of blinded claim-based PoAs include:\n",
        "\n",
        "* **Verifier burden**. Verifiers must process and validate the PoA.\n",
        "* **Issuer burden**: Issuers must create and include blinded PoA inputs in each attestation.\n",
        "* **Not standardized**. A blinded claims based PoA requires standardization and also protocol support.\n",
        "* **Single-use**. Blinded claim values are static unique values and thus single-use only to prevent Verifier linkability.\n",
        "\n",
        "Benefits include:\n",
        "\n",
        "* **Compliant with existing protocols**. A blinded claim based PoA is entirely software based and can be achieved using a separate PoA endpoint / out-of-band channel.\n",
        "* **Separation of concerns**. The PoA does not require WSCD protection. However, a Verifier will only request a PoA if the User proves PoP of WSCD-protected keys in the Combined Presentation.\n",
        "* **Repudiable compositions**. With an IZKP (but not NIZKP) PoA, a Verifier can generate a simulated transcript indistinguishable from a real one, providing Users repudiability against third parties.\n",
        "* **Curve\\algo independence**. With a ZKP-based PoA, you can prove that two keys are associated even across curves and algorithms (e.g., signature and key exchange).\n",
        "\n",
        "### Signature-based PoA  \n",
        "\n",
        "Signature-based PoA uses at least two keypairs in a process that establishes their association. These approaches **do not inherently provide PoA** and instead rely on certified hardware to enforce signing rules. Possible adaptations could leverage:\n",
        "  * **Countersignatures**: One key signs a signature from another key, ensuring both are linked, e.g., $Sign(k_a, Sign(k_b, M))$.\n",
        "  * **Cross-signing**: A private key signs a statement containing another public key, proving their relationship, e.g., $Sign(k_a, K_b)$.\n",
        "  * **Multi-signatures**: Multiple keys jointly create a valid signature. Some schemes, like Schnorr, allow for signature aggregation, e.g., $Sign(k_a, k_b, M)$.\n",
        "\n",
        "There are some major limitation of signature-based PoA.\n",
        "\n",
        "* **Requires certified hardware**. Every signature-based PoA approach relies on certified hardware to enforce signature policies that only allow the generation of PoAs if all involved keys are under the same device's sole control. Without it, an attacker can trivially generate PoAs.\n",
        "* **Repurposed techniques**. A signature-based PoA repurposes cryptographic methods that were not designed to inherently enforce PoA and must be adapted for this purpose:\n",
        "  * Countersignatures are used for stepwise accountability, such as timestamping, document notarization, and email receipt non-repudiation.\n",
        "  * Cross-signing is intended for a trusted entity vouching for another trusted entity's key. It can be used for identity binding; implementations of PGP rely on cross-signing to establish identity binding between a primary key and a subkey.\n",
        "  * Multi-signatures are used for threshold security and collaborative signing.\n",
        "* **Verifier burden**. The Verifier must process and validate the PoA. While not equally complex, signature based PoAs add overhead and requires a peer reviewed standardization process.\n",
        "* **Linkability**. Signature-based PoA publicly links two keys, making it suitable only for one-time-use keys.\n",
        "* **Non-repudiable compositions**. Signature-based PoA creates a permanent, non-repudiable link between two attestations, exceeding the minimal proof required and enabling third-party behavioral profiling.\n",
        "\n",
        "Despite its drawbacks, signature-based PoA offers several benefits:\n",
        "\n",
        "* The cryptographic primitives are widely understood and easy to implement.\n",
        "* Signature-based PoA techniques are highly unlikely to raise patent concerns.\n",
        "* While these techniques require repurposing, they are well-documented, widely used, and supported by clear standards.\n",
        "\n",
        "\n",
        "### Related key PoA\n",
        "\n",
        "A related key PoA establishes an association between public keys based on relationships between their private keys.\n",
        "\n",
        "> NOTE: Related key PoA has known security risks (e.g., with ECDSA) and potential patent concerns, requiring careful and extensive examination.\n",
        "\n",
        "Two primary approaches exist. Both leverage homomorphic relationships between private and public key operations:\n",
        "\n",
        "1. **Key ratio associations**. [Verheul (2025)](https://eprint.iacr.org/2024/1444.pdf) presents a well-developed approach.\n",
        "  * An **association key** is defined as the ratio of private key scalars: $z = p_2 \\cdot p_1^{-1}$.\n",
        "  * The multiplicative structure of $z$ is preserved in the public key domain enabling PoA.\n",
        "  * Based on a modified Schnorr signature.\n",
        "  * Requires both PoA and PoP from the User.\n",
        "  * Depends on certified WSCD capable of arbitrary private key computations.\n",
        "2. **Derived associations with key blinding**. Detailed in BIP-32 and SLIP-0010 (both widely adopted), adapted for an EUDIW context in [ARKG](https://datatracker.ietf.org/doc/draft-bradleylundberg-cfrg-arkg/), and [HDK](https://datatracker.ietf.org/doc/draft-dijkhuis-cfrg-hdkeys/); further detailed in [KBSS](https://datatracker.ietf.org/doc/draft-irtf-cfrg-signature-key-blinding/).\n",
        "  * Applies a blinding factor, $p_b$, to an existing private key $p_1$.\n",
        "  * The blinding factor can be applied additively, $p_1 + p_b$, or multiplicative $p_1 \\cdot p_b$, depending on the scheme and leverages existing key generation subroutines.\n",
        "  * When locally computed the User derives $p_b$ for use with new keys. An Issuer would here require PoP and PoA.\n",
        "  * In joint computation, a KEM ensures that both the User and Issuer can compute the public key association, while only the User derives the private key association.\n",
        "  * Implicitly ensures PoP and PoA requiring proof of neither.\n",
        "  * Explicit PoA possible via Chaum-Pedersen proofs.\n",
        "\n",
        "> NOTE 1: Key generation and PoA are intertwined in key ratio assocations, but separate (and potentially software based) in derived assocation using key blinding.\n",
        "> NOTE 2: Due to the relationships introduced, both approaches require safeguards with malleable schemes like ECDSA to prevent signature forgeries.\n",
        "\n",
        "Both approaches require extensive scrutiny before their benefits and drawbacks can be fully assessed. This discussion aims to contribute to their respective evaluations.\n",
        "\n",
        "As I actively support and contribute to the derived associations via key blinding approach, I would like to initiate this discussion with the following remarks:\n",
        "* Related discussion: See [Topic B](https://github.com/eu-digital-identity-wallet/eudi-doc-architecture-and-reference-framework/discussions/354#discussioncomment-11941084)\n",
        "* **Critical** review of Verheul (2015): Available in this [publicly accessible document](https://drive.google.com/file/d/1zBzYR4ZM5gxt_IdNDOMuaxlztakyjAcv/view?usp=sharing), where all comments are public.\n",
        "\n",
        "I greatly appreciate Verheul's work and the effort invested; my critique is intended to be constructive and support further improvement. To this end, I offer the following comments:\n",
        "\n",
        "* The security requirements are heuristically derived from a specific use case context that may not align with EUDIW's needs.\n",
        "* Particularly, I challenge SW2 in Verheul's work, but also raise issues with SW1.\n",
        "* Seemingly, due to the single-generator constraint and potentially overly restrictive security assumptions, Verheul's approach introduces three key requirements:\n",
        "  * (a) an association key,\n",
        "  * (b) a WSCD capable of arbitrary private key operations, and\n",
        "  * (c) a heavily modified Schnorr algorithm.\n",
        "* I am concerned about the relationship introduced in (a) and that (c) deviates significantly from a standard Schnorr or Chaum-Pedersen proof.\n",
        "* If (b) is required, it raises the question of why (a) and (c) are needed at all, given that simpler methods (c.f. Appendix B) may exist.\n",
        "* Verheul's approach blurs the distinction between Proof of Possession (PoP) and Proof of Association (PoA), which may not be ideal for modular security designs.\n",
        "* The HDK approach I am involved in has received criticism as discussed in Topic B.\n",
        "\n",
        "## Achieving Valid Composition\n",
        "\n",
        "I have no idea how to do this generally. The only viable ways I can think of are:\n",
        "\n",
        "1. limit attribute compositions to a single identity subject, and\n",
        "2. a claims based approach where attributes evidence valid compositions (e.g., values in the first attestation for `parents` that can be matched with the corresponding subject identifer values in the second attestation)."
      ],
      "metadata": {
        "id": "QS9g4Cql-7-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appendices"
      ],
      "metadata": {
        "id": "rFTtCOtjAnaQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Appendix A: A third party repudiable ZKP-based PoA"
      ],
      "metadata": {
        "id": "JqEwwotEAo-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install ecpy\n",
        "import secrets\n",
        "from ecpy.curves    import Curve, Point"
      ],
      "metadata": {
        "id": "jOvYDQzZB0S8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An EC setup requires a curve and two generators, $(G, H)$. $G$, is the curve's standard generator, while security requires $H$ to be chosen using a publicly verifiable random process. We need to ensure each Issuer generates a distinct generator and eliminate as many attack vectors as possible.\n",
        "\n",
        "One potential solution is a KEM-seeded Hash-to-Curve ([RFC 9180](https://www.rfc-editor.org/rfc/rfc9180.html) with [RFC 9380](https://www.rfc-editor.org/rfc/rfc9380.html)). The KEM part ensures Issuer distinct generators, while Hash-to-Curve outputs a generator with unknown scalar.\n",
        "\n",
        "Here, we just pick $H$ at random."
      ],
      "metadata": {
        "id": "l191vdQO2DC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The curves\n",
        "crv = Curve.get_curve(\"secp256r1\")\n",
        "order = crv.order\n",
        "G  = crv.generator\n",
        "\n",
        "# 1st blind generator\n",
        "H_1 = secrets.randbelow(order) * G\n",
        "\n",
        "# 2nd blind generator\n",
        "H_2 = secrets.randbelow(order) * G"
      ],
      "metadata": {
        "id": "oett8DA4S64z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The PID issuer includes a unique random value, `poa_seed`, in the PID attestation. Note that this value is **NOT** intended to act as a unique identifier for the User, but as a PoA input."
      ],
      "metadata": {
        "id": "LTk6mBRw6Z3M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hNaHNTZe-yj8"
      },
      "outputs": [],
      "source": [
        "# The PID issuer includes a PoA seed in the attestation\n",
        "poa_seed = secrets.randbelow(order)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next step, two additional distinct Issuers rely on the poa_seed to generate a blinded version each, $H_1, H_2$. Note that only the User sees both blinded values at this step."
      ],
      "metadata": {
        "id": "vg4xUMr47KlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Attestation Issuer 1\n",
        "blind_poa_input_1 = poa_seed * H_1\n",
        "\n",
        "#Attestation Issuer 2\n",
        "blind_poa_input_2 = poa_seed * H_2"
      ],
      "metadata": {
        "id": "AV2b5VohB8mq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The User can now reveal the two blinded PoA values to a Verifier. The Verifier will require the User to generate a PoA between $A$ and $B$.\n",
        "\n",
        "The User can generate a PoA proof using e.g., a PODLE like the Chaum-Pedersen protocol, which allows the User to prove that it knows two discrete logarithms $y_1 = h_1^r$ and $y_2 = h_2^r$ with respect to two distinct generators $h_1, h_2$.\n",
        "\n",
        "The Verifier accepts the proof of discrete log equivalence as a proof of association."
      ],
      "metadata": {
        "id": "wErRuC-b9CCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# User samples a random nonce\n",
        "r = secrets.randbelow(order)\n",
        "\n",
        "# The User shares two commitments with the Verifier\n",
        "P = r * H_1\n",
        "Q = r * H_2\n",
        "\n",
        "# A random challenge is produced either by the Verifier or using a random oracle.\n",
        "# Here we just sample from random\n",
        "# A repudiable proof requires Verifier picked c thus IZKP\n",
        "# A NIZKP with Fiat-Shamir is always third party non-repudiable\n",
        "c = secrets.randbits(256)\n",
        "\n",
        "# The user computes s\n",
        "s = r + c * poa_seed\n",
        "\n",
        "# The Verifier verifies the PODLE using challenge c, recieved values (s, P, Q), and blinded PoAs\n",
        "assert (s * H_1 == P + (blind_poa_input_1 * c))\n",
        "assert (s * H_2 == Q + (blind_poa_input_2 * c))"
      ],
      "metadata": {
        "id": "ArztJxG-9BCZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ZKP property means that there exists a simulator that can produce proofs indistinguishable from real ones even without knowledge of the secret. This is useful when a Proof of Association (PoA) needs to be repudiable. Works only with IZKP and not NIZKP (the latter does not permit the challenge to be selected before R).\n",
        "\n",
        "The **real proof**, given $Y = x \\cdot H_1$ and $Z = x \\cdot H_2$, where the Prover knows $x$ consists of:\n",
        "\n",
        "* Prover commitments: $P = r \\cdot H_1, Q = r \\cdot H_2$\n",
        "* A random challenge $c$\n",
        "* Prover computation: $s = r + c \\cdot x $\n",
        "\n",
        "The **simulated proof** is:\n",
        "\n",
        "* Pick $s$ at random\n",
        "* Compute $P = s \\cdot H_1 - c \\cdot Y, Q = s \\cdot H_2 - c \\cdot Z$\n",
        "\n",
        "The transcript is verified with:\n",
        "\n",
        "* $s \\cdot H_1 = P + c \\cdot Y$\n",
        "* $s \\cdot H_2 = Q + c \\cdot Z$\n",
        "\n",
        "Since the simulated transcript is computationally indistinguishable from a real one, a third party cannot determine whether the Prover actually participated. This enables repudiability of the PoA, meaning the Prover can plausibly deny involvement in the proof."
      ],
      "metadata": {
        "id": "tucwHtFvT0hJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apprendix B: Simple PoA when WSCD supports arbitrary operations"
      ],
      "metadata": {
        "id": "Bz1FXkQAhAx9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alg 1-2 in Verheul presents a way to generate a PoA between two private keys protected by the same WSCD. Verheul's proposal builds on the assumption that the Prover \"has full control over both private keys\" and can \"do arbitrary mathematical operations with these.\" This is seemingly required because of the limitation to rely on a the curve specified generator $G$ only.\n",
        "\n",
        "One possible argument raised against Alg 1-2 is that they are overly complex given that the assumption is *full* control. A WSCD that has full control can simplify the PoA."
      ],
      "metadata": {
        "id": "syikHnUJhWv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the same notation as Alg 1-2\n",
        "p_1 = secrets.randbelow(order)\n",
        "p_2 = secrets.randbelow(order)\n",
        "\n",
        "# The two public keys the Prover wants to generate a PoA for\n",
        "P_1 = p_1 * G\n",
        "P_2 = p_2 * G\n",
        "\n",
        "# Instead of an association key, the WSCD outputs a third value z\n",
        "z = p_1 + p_2\n",
        "\n",
        "# The verification is now\n",
        "P_1 + P_2 == z*G"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3Gq_-5g9G4S8",
        "outputId": "91b19b51-b522-4454-d86c-613c1de14190"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above approach is extendable to more than two private keys. Given the scalar sum $z = \\sum_{i=0}^n{p_i}$, the corresponding public key sum is: $\\sum_{i=0}^n{P_i} = z \\cdot G$, which serves as a combined PoP and PoA.\n",
        "\n",
        "Since each private key is a random value, their sum is indistinguishable from a randomly chosen scalar from the same group. Knowledge of $z$ does not leak information about either $p_1$ or $p_2$ without additional information; it is information theoretically secure.\n",
        "\n",
        "An attacker with knowlege of $(P_1, P_2, z)$ cannot extract either $p_1$ or $p_2$ from $(P_1, P_2)$ because that would break ECDLP.\n",
        "\n",
        "Seemingly, an exhaustive search is the best approach for the attacker in the case of single-use-keys, which is the same as the attacker has for guessing either $p_1$ or $p_2$ from $P_1$ or $P_2$."
      ],
      "metadata": {
        "id": "ZzlN4ZCwkvR-"
      }
    }
  ]
}